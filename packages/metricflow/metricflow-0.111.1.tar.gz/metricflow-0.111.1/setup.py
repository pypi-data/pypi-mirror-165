# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['metricflow',
 'metricflow.api',
 'metricflow.cli',
 'metricflow.configuration',
 'metricflow.constraints',
 'metricflow.dag',
 'metricflow.dataflow',
 'metricflow.dataflow.builder',
 'metricflow.dataset',
 'metricflow.engine',
 'metricflow.errors',
 'metricflow.execution',
 'metricflow.inference',
 'metricflow.inference.context',
 'metricflow.inference.renderer',
 'metricflow.inference.rule',
 'metricflow.inference.solver',
 'metricflow.model',
 'metricflow.model.objects',
 'metricflow.model.objects.constraints',
 'metricflow.model.objects.elements',
 'metricflow.model.parsing',
 'metricflow.model.semantics',
 'metricflow.model.transformations',
 'metricflow.model.validations',
 'metricflow.naming',
 'metricflow.plan_conversion',
 'metricflow.protocols',
 'metricflow.query',
 'metricflow.sql',
 'metricflow.sql.optimizer',
 'metricflow.sql.render',
 'metricflow.sql_clients',
 'metricflow.telemetry',
 'metricflow.telemetry.handlers',
 'metricflow.test',
 'metricflow.test.api',
 'metricflow.test.cli',
 'metricflow.test.constraints',
 'metricflow.test.dataflow',
 'metricflow.test.dataflow.builder',
 'metricflow.test.dataset',
 'metricflow.test.execution',
 'metricflow.test.fixtures',
 'metricflow.test.inference',
 'metricflow.test.inference.context',
 'metricflow.test.inference.renderer',
 'metricflow.test.inference.rule',
 'metricflow.test.inference.solver',
 'metricflow.test.integration',
 'metricflow.test.model',
 'metricflow.test.model.parsing',
 'metricflow.test.model.semantics',
 'metricflow.test.model.transformations',
 'metricflow.test.model.validations',
 'metricflow.test.plan_conversion',
 'metricflow.test.plan_conversion.dataflow_to_sql',
 'metricflow.test.plan_conversion.instance_converters',
 'metricflow.test.query',
 'metricflow.test.sql',
 'metricflow.test.sql.optimizer',
 'metricflow.test.sql_clients',
 'metricflow.test.telemetry',
 'metricflow.test.time',
 'metricflow.time']

package_data = \
{'': ['*'],
 'metricflow.cli': ['sample_models/*'],
 'metricflow.model.parsing': ['schemas/*'],
 'metricflow.test': ['snapshots/test_column_pruner.py/SqlQueryPlan/*',
                     'snapshots/test_convert_data_source.py/SqlQueryPlan/BigQuerySqlClient/*',
                     'snapshots/test_convert_data_source.py/SqlQueryPlan/DuckDbSqlClient/*',
                     'snapshots/test_convert_data_source.py/SqlQueryPlan/PostgresSqlClient/*',
                     'snapshots/test_convert_data_source.py/SqlQueryPlan/RedshiftSqlClient/*',
                     'snapshots/test_convert_data_source.py/SqlQueryPlan/SnowflakeSqlClient/*',
                     'snapshots/test_data_warehouse_tasks.py/data_warehouse_validation_model/BigQuerySqlClient/*',
                     'snapshots/test_data_warehouse_tasks.py/data_warehouse_validation_model/DuckDbSqlClient/*',
                     'snapshots/test_data_warehouse_tasks.py/data_warehouse_validation_model/PostgresSqlClient/*',
                     'snapshots/test_data_warehouse_tasks.py/data_warehouse_validation_model/RedshiftSqlClient/*',
                     'snapshots/test_data_warehouse_tasks.py/data_warehouse_validation_model/SnowflakeSqlClient/*',
                     'snapshots/test_data_warehouse_tasks.py/data_warehouse_validation_model/SqliteSqlClient/*',
                     'snapshots/test_dataflow_plan_builder.py/DataflowPlan/*',
                     'snapshots/test_dataflow_to_execution.py/ExecutionPlan/BigQuerySqlClient/*',
                     'snapshots/test_dataflow_to_execution.py/ExecutionPlan/DuckDbSqlClient/*',
                     'snapshots/test_dataflow_to_execution.py/ExecutionPlan/PostgresSqlClient/*',
                     'snapshots/test_dataflow_to_execution.py/ExecutionPlan/RedshiftSqlClient/*',
                     'snapshots/test_dataflow_to_execution.py/ExecutionPlan/SnowflakeSqlClient/*',
                     'snapshots/test_dataflow_to_execution.py/ExecutionPlan/SqliteSqlClient/*',
                     'snapshots/test_dataflow_to_sql_plan.py/DataflowPlan/*',
                     'snapshots/test_dataflow_to_sql_plan.py/SqlQueryPlan/*',
                     'snapshots/test_dataflow_to_sql_plan.py/SqlQueryPlan/BigQuerySqlClient/*',
                     'snapshots/test_dataflow_to_sql_plan.py/SqlQueryPlan/DuckDbSqlClient/*',
                     'snapshots/test_dataflow_to_sql_plan.py/SqlQueryPlan/PostgresSqlClient/*',
                     'snapshots/test_dataflow_to_sql_plan.py/SqlQueryPlan/RedshiftSqlClient/*',
                     'snapshots/test_dataflow_to_sql_plan.py/SqlQueryPlan/SnowflakeSqlClient/*',
                     'snapshots/test_dataflow_to_sql_plan.py/SqlQueryPlan/SqliteSqlClient/*',
                     'snapshots/test_engine_specific_rendering.py/SqlQueryPlan/BigQuerySqlClient/*',
                     'snapshots/test_engine_specific_rendering.py/SqlQueryPlan/DuckDbSqlClient/*',
                     'snapshots/test_engine_specific_rendering.py/SqlQueryPlan/PostgresSqlClient/*',
                     'snapshots/test_engine_specific_rendering.py/SqlQueryPlan/RedshiftSqlClient/*',
                     'snapshots/test_engine_specific_rendering.py/SqlQueryPlan/SnowflakeSqlClient/*',
                     'snapshots/test_metric_time_dimension_to_sql.py/SqlQueryPlan/*',
                     'snapshots/test_metric_time_dimension_to_sql.py/SqlQueryPlan/BigQuerySqlClient/*',
                     'snapshots/test_metric_time_dimension_to_sql.py/SqlQueryPlan/DuckDbSqlClient/*',
                     'snapshots/test_metric_time_dimension_to_sql.py/SqlQueryPlan/PostgresSqlClient/*',
                     'snapshots/test_metric_time_dimension_to_sql.py/SqlQueryPlan/RedshiftSqlClient/*',
                     'snapshots/test_metric_time_dimension_to_sql.py/SqlQueryPlan/SnowflakeSqlClient/*',
                     'snapshots/test_metric_time_dimension_to_sql.py/SqlQueryPlan/SqliteSqlClient/*',
                     'snapshots/test_plot_time_dimension_to_sql.py/SqlQueryPlan/*',
                     'snapshots/test_plot_time_dimension_to_sql.py/SqlQueryPlan/SqliteSqlClient/*',
                     'snapshots/test_rendered_query.py/MetricFlowExplainResult/BigQuerySqlClient/*',
                     'snapshots/test_rendered_query.py/MetricFlowExplainResult/DuckDbSqlClient/*',
                     'snapshots/test_rendered_query.py/MetricFlowExplainResult/PostgresSqlClient/*',
                     'snapshots/test_rendered_query.py/MetricFlowExplainResult/RedshiftSqlClient/*',
                     'snapshots/test_rendered_query.py/MetricFlowExplainResult/SnowflakeSqlClient/*',
                     'snapshots/test_rendered_query.py/MetricFlowExplainResult/SqliteSqlClient/*',
                     'snapshots/test_rewriting_sub_query_reducer.py/SqlQueryPlan/*',
                     'snapshots/test_sql_plan_render.py/SqlQueryPlan/BigQuerySqlClient/*',
                     'snapshots/test_sql_plan_render.py/SqlQueryPlan/DuckDbSqlClient/*',
                     'snapshots/test_sql_plan_render.py/SqlQueryPlan/PostgresSqlClient/*',
                     'snapshots/test_sql_plan_render.py/SqlQueryPlan/RedshiftSqlClient/*',
                     'snapshots/test_sql_plan_render.py/SqlQueryPlan/SnowflakeSqlClient/*',
                     'snapshots/test_sub_query_reducer.py/SqlQueryPlan/*',
                     'snapshots/test_table_alias_simplifier.py/SqlQueryPlan/*'],
 'metricflow.test.fixtures': ['model_yamls/composite_identifier_model/*',
                              'model_yamls/config_linter_model/*',
                              'model_yamls/data_warehouse_validation_model/data_sources/*',
                              'model_yamls/extended_date_model/data_sources/*',
                              'model_yamls/join_types_model/*',
                              'model_yamls/multi_hop_join_model/partitioned_data_sources/*',
                              'model_yamls/multi_hop_join_model/unpartitioned_data_sources/*',
                              'model_yamls/non_ds_model/*',
                              'model_yamls/simple_model/*',
                              'model_yamls/simple_model/data_sources/*'],
 'metricflow.test.integration': ['test_cases/*']}

install_requires = \
['GitPython>=3.1.27,<4.0.0',
 'Jinja2>=2.11.3',
 'MarkupSafe==2.0.1',
 'PyYAML>=5.4.1,<6.0.0',
 'SQLAlchemy>=1.4.27,<2.0.0',
 'click>=7.1.2',
 'croniter>=1.3.4,<2.0.0',
 'duckdb-engine>=0.1.8,<0.2.0',
 'duckdb==0.3.4',
 'fuzzywuzzy>=0.18.0,<0.19.0',
 'google-cloud-bigquery==2.34.2',
 'graphviz==0.18.2',
 'halo>=0.0.31,<0.0.32',
 'jsonschema==3.2.0',
 'more-itertools==8.10.0',
 'moz-sql-parser>=4.40.21126,<5.0.0',
 'numpy>=1.22.2',
 'pandas==1.2.4',
 'psycopg2>=2.9.3,<3.0.0',
 'pycron>=3.0.0,<4.0.0',
 'pydantic>=1.9.0,<2.0.0',
 'python-Levenshtein>=0.12.2,<0.13.0',
 'python-dateutil==2.8.2',
 'requests>=2.27.1,<3.0.0',
 'ruamel.yaml>=0.17.21,<0.18.0',
 'rudder-sdk-python>=1.0.3,<2.0.0',
 'snowflake-connector-python>=2.7.8',
 'snowflake-sqlalchemy==1.2.3',
 'sqlalchemy-bigquery>=1.4.3,<2.0.0',
 'sqlalchemy-redshift==0.8.1',
 'sqlalchemy2-stubs>=0.0.2-alpha.21,<0.0.3',
 'tabulate==0.8.9',
 'update-checker>=0.18.0,<0.19.0',
 'yamllint>=1.26.3,<2.0.0']

entry_points = \
{'console_scripts': ['mf = metricflow.cli.main:cli']}

setup_kwargs = {
    'name': 'metricflow',
    'version': '0.111.1',
    'description': 'Translates a simple metric definition into reusable SQL and executes it against the SQL engine of your choice.',
    'long_description': '<p align="center">\n<img src="https://github.com/transform-data/metricflow/raw/main/assets/MetricFlow_logo.png" />\n<br /><br />\n</p>\n\n# Welcome to MetricFlow\n\nSee our latest updates in the [Metricflow Changelog](https://github.com/transform-data/metricflow/blob/main/CHANGELOG.md)!\n\nMetricFlow translates a simple metric definition into reusable SQL, and executes it against the SQL engine of your choice. This makes it easy to get consistent metric output broken down by attributes (dimensions) of interest.\n\nMetricFlow is a computational framework for building and maintaining consistent metric logic. The name comes from the approach taken to generate metrics. Using the user-defined semantic model, a query is first compiled into a metric dataflow plan. The plan is then converted to an abstract SQL object model, optimized, and rendered to engine-specific SQL.\n\nMetricFlow provides a set of abstractions that help you construct complicated logic and dynamically generate queries to handle:\n\n- Complex metric types such as ratio, expression, and cumulative\n- Multi-hop joins between fact and dimension sources\n- Metric aggregation to different time granularities\n- And so much more\n\nAs a developer, you can also use MetricFlow\'s interfaces to construct APIs for integrations to bring metrics into downstream tools in your data stack.\n\nMetricFlow itself acts as a semantic layer, compiling the semantic information described in the MetricFlow spec to SQL that can be executed against the data warehouse and served to downstream applications. It acts as a proxy, translating metric requests in the form of “metrics by dimensions” into SQL queries that traverse the data warehouse and the underlying semantic structure to resolve every possible combination of metric and dimension.\n\n## Getting Started\n\n### Install MetricFlow\n\nIf you do not have postgres on your machine, first install Postgres:\n- Postgres provides [pre-built packages for download and installation](https://www.postgresql.org/download/)\n- Mac users might prefer to use Homebrew: `brew install postgresql`\n\nIf you would like to visualize metric dataflow plans via CLI, install Graphviz:\n- Graphviz provides [pre-built packages for download and installation](https://www.graphviz.org/download/)\n- Mac users might prefer to use Homebrew: `brew install graphviz`\n\nThe visualizations are in an early state of development, but look similar to:\n\n<p align="center">\n<img src="https://github.com/transform-data/metricflow/raw/main/assets/example_plan.svg" height="500"/>\n<br /><br />\n</p>\n\nThen, proceed with the regular installation as follows:\n\nMetricFlow can be installed from PyPi for use as a Python library with the following command:\n\n```\npip install metricflow\n```\n\nOnce installed, MetricFlow can be setup and connected to a data warehouse by following the instructions after issuing the command:\n\n```\nmf setup\n```\n\nIn case you don\'t have a connection to a data warehouse available and want a self-contained demo, DuckDB can be selected.\n\nTo see what MetricFlow can do without custom configurations, start the tutorial by running:\n\n```\nmf tutorial\n```\n\nTo get up and running with your own metrics, you should rely on MetricFlow’s documentation available at [MetricFlow docs](https://docs.transform.co/docs/metricflow/guides/introduction).\n\n### Tutorial\n\n```\nmf tutorial # optionally add `--skip-dw` if you have already confirmed your datawarehouse connection works\n```\n\nFor reference, the tutorial steps are below:\n\n```\n🤓 Please run the following steps,\n\n    1.  In \'{$HOME}/.metricflow/config.yml\', `model_path` should be \'{$HOME}/.metricflow/sample_models\'.\n    2.  Try validating your data model: `mf validate-configs`\n    3.  Check out your metrics: `mf list-metrics`\n    4.  Check out dimensions for your metric `mf list-dimensions --metric-names transactions`\n    5.  Query your first metric: `mf query --metrics transactions --dimensions metric_time --order metric_time`\n    6.  Show the SQL MetricFlow generates:\n        `mf query --metrics transactions --dimensions metric_time --order metric_time --explain`\n    7.  Visualize the plan:\n        `mf query --metrics transactions --dimensions metric_time --order metric_time --explain --display-plans`\n        * This only works if you have graphviz installed - see README.\n    8.  Add another dimension:\n        `mf query --metrics transactions --dimensions metric_time,customer__country --order metric_time`\n    9.  Add a coarser time granularity:\n        `mf query --metrics transactions --dimensions metric_time__week --order metric_time__week`\n    10. Try a more complicated query:\n        `mf query \\\n          --metrics transactions,transaction_usd_na,transaction_usd_na_l7d --dimensions metric_time,is_large \\\n          --order metric_time --start-time 2022-03-20 --end-time 2022-04-01`\n        * You can also add `--explain --display-plans`.\n    11. For more ways to interact with the sample models, go to\n        ‘https://docs.transform.co/docs/metricflow/metricflow-tutorial’.\n    12. Once you’re done, run `mf tutorial --skip-dw --drop-tables` to drop the sample tables.\n```\n\n\n## Core Tenets\n\nThe framework relies on a set of core tenets:\n\n- **DRY (Don’t Repeat Yourself)**: This principle is the core objective of the underlying MetricFlow spec. Duplication of logic leads to incorrectly constructed metrics and should be avoided through thoughtfully-designed abstractions.\n- **SQL-centric compilation**: Metric logic should never be constructed in a black-box. This SQL-centric approach to metric construction means that metric logic remains broadly accessible and introspectable.\n- **Maximal Flexibility**: Construct any metric on any data model aggregated to any dimension. There are escape hatches, but we continually work to make them unnecessary.\n\n## Features\n\nKey features of MetricFlow include:\n\n- **Metrics as Code:** MetricFlow\'s metric spec allows you to define a wide-range of metrics through a clean set of abstractions that encourage DRY expression of logic in YAML and SQL.\n- **SQL Compilation:** Generate SQL to build metrics, without the need to repeatedly express the same joins, aggregations, filters and expressions from your data warehouse in order to construct datasets for consumption.\n- **DW Connectors**: Support for data warehouse (DW) connectors give the open-source community the power to contribute to DW-specific optimizations and support. DW connectors allow users to construct metric logic to various data warehouses.\n- **Command Line Interface (CLI)**: Pull data into a local context for testing and development workflows.\n- **Python Library**: Pull metrics into local Python environments such as Jupyter or other analytical interfaces.\n- **Materializations:** Define a set of metrics and a set of dimensions that you want to materialize to the data warehouse. This enables rapid construction of denormalized datasets back to the warehouse.\n\n## Contributing and Code of Conduct\n\nThis project will be a place where people can easily contribute high-quality updates in a supportive environment.\n\nYou might wish to read our [code of conduct](http://community.transform.co/metricflow-signup) and <LINK> engineering practices </LINK> before diving in.\n\nTo get started on direct contributions, head on over to our [contributor guide](https://github.com/transform-data/metricflow/blob/main/CONTRIBUTING.md).\n\n## Resources\n\n- [Website](https://transform.co/metricflow)\n- [Documentation](https://docs.transform.co/docs/overview/metricflow-overview)\n- [Slack Community](https://community.transform.co/metricflow-signup)\n- [MetricFlow Git Repository](https://github.com/transform-data/metricflow)\n- [CHANGELOG.md](https://github.com/transform-data/metricflow/blob/main/CHANGELOG.md)\n\n## License\n\nMetricFlow is open source software. The project relies on several licenses including AGPL-3.0-or-later and Apache (specified at folder level).\n\nMetricFlow is built by [Transform](https://transform.co/), the company behind the first metrics store.\n',
    'author': 'Transform',
    'author_email': 'hello@transformdata.io',
    'maintainer': None,
    'maintainer_email': None,
    'url': 'https://transform.co/metricflow',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'entry_points': entry_points,
    'python_requires': '>=3.8,<3.10',
}


setup(**setup_kwargs)
