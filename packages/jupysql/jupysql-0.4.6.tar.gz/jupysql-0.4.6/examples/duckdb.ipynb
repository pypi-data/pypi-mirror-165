{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3453f0d7",
   "metadata": {},
   "source": [
    "# DuckDB\n",
    "\n",
    "\n",
    "```{dropdown} Required packages\n",
    "~~~\n",
    "pip install duckdb duckdb-engine pyarrow\n",
    "~~~\n",
    "```\n",
    "\n",
    "```{tip}\n",
    "Try this locally:\n",
    "\n",
    "~~~\n",
    "pip install k2s -U && k2s get ploomber/jupysql/master/examples/duckdb.ipynb\n",
    "~~~\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "## Reading a SQLite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43a0427",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f408cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from pathlib import Path\n",
    "from sqlite3 import connect\n",
    "\n",
    "# download sample database\n",
    "if not Path('my.db').is_file():\n",
    "    url = \"https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sqlite\"\n",
    "    urllib.request.urlretrieve(url, 'my.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86c3eb2",
   "metadata": {},
   "source": [
    "We'll use `sqlite_scanner` extension to load a sample SQLite databse into DuckDB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268eef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql duckdb:///\n",
    "INSTALL 'sqlite_scanner';\n",
    "LOAD 'sqlite_scanner';\n",
    "CALL sqlite_attach('my.db');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b591bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM track LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bc90cc",
   "metadata": {},
   "source": [
    "## Plotting large datasets\n",
    "\n",
    "*New in version 0.4.4*\n",
    "\n",
    "```{note}\n",
    "This is a beta feature, please [join our community](https://ploomber.io/community) and let us know what plots we should add next!\n",
    "```\n",
    "\n",
    "\n",
    "This section demonstrates how we can efficiently plot large datasets with DuckDB and JupySQL without blowing up our machine's memory.\n",
    "\n",
    "We first download a sample data: NYC Taxi data splitted in 3 parquet files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9263a464",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MONTHS = 3\n",
    "\n",
    "# https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\n",
    "for i in range(1, N_MONTHS + 1):\n",
    "    filename = f'yellow_tripdata_2021-{str(i).zfill(2)}.parquet'\n",
    "    if not Path(filename).is_file():\n",
    "        print(f'Downloading: {filename}')\n",
    "        url = f'https://d37ci6vzurychx.cloudfront.net/trip-data/{filename}'\n",
    "        urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db61c604",
   "metadata": {},
   "source": [
    "In total, this contains more then 4.6M observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c28595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT count(*) FROM 'yellow_tripdata_2021-*.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323a3e0d",
   "metadata": {},
   "source": [
    "Now, let's keep track of how much  memory this Python session is using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920384c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import os\n",
    "\n",
    "def memory_usage():\n",
    "    \"\"\"Print how much memory we're using\n",
    "    \"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    total = process.memory_info().rss / 10 ** 9\n",
    "    print(f'Using: {total:.1f} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34296604",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba1511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sql import plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb231273",
   "metadata": {},
   "source": [
    "Let's use JupySQL to get a histogram of `trip_distance` across all 12 files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f59fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.histogram('yellow_tripdata_2021-*.parquet', 'trip_distance', bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee75465",
   "metadata": {},
   "source": [
    "We have some outliers, let's find the 99th percentile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eac353",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT percentile_disc(0.99) WITHIN GROUP (ORDER BY trip_distance),\n",
    "FROM 'yellow_tripdata_2021-*.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade4fb4d",
   "metadata": {},
   "source": [
    "We now write a query to remove everything above that number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b90fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql --save no_outliers --no-execute\n",
    "SELECT trip_distance\n",
    "FROM 'yellow_tripdata_2021-*.parquet'\n",
    "WHERE trip_distance < 18.93"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b8394",
   "metadata": {},
   "source": [
    "Now we create a new histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcad82b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.histogram('no_outliers', 'trip_distance', bins=50, with_=['no_outliers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb11dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12105c72",
   "metadata": {},
   "source": [
    "We see that memory usage increase just a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5d7419",
   "metadata": {},
   "source": [
    "## Benchmark: Using pandas\n",
    "\n",
    "We now repeat the same process using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187dab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfee65f",
   "metadata": {},
   "source": [
    "Data loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688746e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = []\n",
    "\n",
    "# https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\n",
    "for i in range(1, N_MONTHS):\n",
    "    filename = f'yellow_tripdata_2021-{str(i).zfill(2)}.parquet'\n",
    "    t = pyarrow.parquet.read_table(filename)\n",
    "    tables.append(t)\n",
    "\n",
    "table = pyarrow.concat_tables(tables)\n",
    "df = pyarrow.concat_tables(tables).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89065acf",
   "metadata": {},
   "source": [
    "First histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897bd2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(df.trip_distance, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60475ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = df.trip_distance.quantile(.99)\n",
    "cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e819cd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = df.trip_distance[df.trip_distance < cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a689de",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(subset, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313801fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e3b7d6",
   "metadata": {},
   "source": [
    "**We're using 1.6GB of memory just by loading the data with pandas!**\n",
    "\n",
    "Try re-running the notebook with the full 12 months (change `N_MONTHS` to `12` in the earlier cell), and you'll see that memory usage blows up to 8GB.\n",
    "\n",
    "Even deleting the dataframes does not completely free up the memory ([explanation here](https://stackoverflow.com/a/39377643/709975)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42639bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df, subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d416ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_usage()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
