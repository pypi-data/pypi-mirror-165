Metadata-Version: 2.1
Name: flockfysh
Version: 0.0.2.1a0
Summary: A simple images vending machine that gives more than it gets.
Home-page: https://github.com/teamnebulaco/flockfysh
License: BSD
Keywords: images,flockfysh,dataset,ai,web scraping
Author: Team Nebula
Author-email: teamnebulaco@gmail.com
Requires-Python: >=3.8,<3.12
Classifier: License :: Other/Proprietary License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Requires-Dist: CacheControl (==0.12.11)
Requires-Dist: GitPython (==3.1.27)
Requires-Dist: Markdown (==3.4.1)
Requires-Dist: MarkupSafe (==2.1.1)
Requires-Dist: Pillow (==9.0.1)
Requires-Dist: PySocks (==1.7.1)
Requires-Dist: PyWavelets (==1.3.0)
Requires-Dist: PyYAML (==6.0)
Requires-Dist: Pygments (==2.12.0)
Requires-Dist: SecretStorage (==3.3.3)
Requires-Dist: Werkzeug (==2.2.1)
Requires-Dist: absl-py (==1.2.0)
Requires-Dist: aiohttp (==3.8.1)
Requires-Dist: aiosignal (==1.2.0)
Requires-Dist: albumentations (==1.2.1)
Requires-Dist: asttokens (==2.0.5)
Requires-Dist: async-timeout (==4.0.2)
Requires-Dist: async_generator (==1.10)
Requires-Dist: attrs (==22.1.0)
Requires-Dist: backcall (==0.2.0)
Requires-Dist: beautifulsoup4 (==4.11.1)
Requires-Dist: bs4 (==0.0.1)
Requires-Dist: cachetools (==5.2.0)
Requires-Dist: cachy (==0.3.0)
Requires-Dist: certifi (==2021.5.30)
Requires-Dist: cffi (==1.15.1)
Requires-Dist: chardet (==4.0.0)
Requires-Dist: charset-normalizer (==2.1.0)
Requires-Dist: cleo (==0.8.1)
Requires-Dist: clikit (==0.6.2)
Requires-Dist: crashtest (==0.3.1)
Requires-Dist: cryptography (==37.0.4)
Requires-Dist: cycler (==0.10.0)
Requires-Dist: datasets (==2.4.0)
Requires-Dist: decorator (==5.1.1)
Requires-Dist: dill (==0.3.5.1)
Requires-Dist: distlib (==0.3.6)
Requires-Dist: executing (==0.9.1)
Requires-Dist: filelock (==3.7.1)
Requires-Dist: fonttools (==4.34.4)
Requires-Dist: frozenlist (==1.3.1)
Requires-Dist: fsspec (==2022.7.1)
Requires-Dist: future (==0.18.2)
Requires-Dist: gitdb (==4.0.9)
Requires-Dist: glob2 (==0.7)
Requires-Dist: google-auth (==2.10.0)
Requires-Dist: google-auth-oauthlib (==0.4.6)
Requires-Dist: grpcio (==1.47.0)
Requires-Dist: h11 (==0.13.0)
Requires-Dist: html5lib (==1.1)
Requires-Dist: huggingface-hub (==0.8.1)
Requires-Dist: idna (==2.10)
Requires-Dist: imageio (==2.21.0)
Requires-Dist: importlib-metadata (==4.12.0)
Requires-Dist: imutils (==0.5.4)
Requires-Dist: ipython (==8.4.0)
Requires-Dist: jedi (==0.18.1)
Requires-Dist: jeepney (==0.8.0)
Requires-Dist: joblib (==1.1.0)
Requires-Dist: kaggle (==1.5.12)
Requires-Dist: keyring (==23.8.2)
Requires-Dist: kiwisolver (==1.3.1)
Requires-Dist: lockfile (==0.12.2)
Requires-Dist: lxml (==4.9.1)
Requires-Dist: matplotlib (==3.5.2)
Requires-Dist: matplotlib-inline (==0.1.3)
Requires-Dist: msgpack (==1.0.4)
Requires-Dist: multidict (==6.0.2)
Requires-Dist: multiprocess (==0.70.13)
Requires-Dist: networkx (==2.8.5)
Requires-Dist: numpy (==1.23.1)
Requires-Dist: oauthlib (==3.2.0)
Requires-Dist: opencv-python (==4.2.0.32)
Requires-Dist: opencv-python-headless (==4.2.0.32)
Requires-Dist: outcome (==1.2.0)
Requires-Dist: packaging (==20.9)
Requires-Dist: pandas (==1.4.3)
Requires-Dist: parso (==0.8.3)
Requires-Dist: pastel (==0.2.1)
Requires-Dist: pefile (==2022.5.30)
Requires-Dist: pexpect (==4.8.0)
Requires-Dist: pickleshare (==0.7.5)
Requires-Dist: pkginfo (==1.8.3)
Requires-Dist: platformdirs (==2.5.2)
Requires-Dist: poetry (==1.1.15)
Requires-Dist: poetry-core (==1.0.8)
Requires-Dist: prompt-toolkit (==3.0.30)
Requires-Dist: protobuf (==3.19.4)
Requires-Dist: psutil (==5.9.1)
Requires-Dist: ptyprocess (==0.7.0)
Requires-Dist: pure-eval (==0.2.2)
Requires-Dist: pyOpenSSL (==22.0.0)
Requires-Dist: pyarrow (==9.0.0)
Requires-Dist: pyasn1 (==0.4.8)
Requires-Dist: pyasn1-modules (==0.2.8)
Requires-Dist: pycparser (==2.21)
Requires-Dist: pylev (==1.4.0)
Requires-Dist: pyparsing (==2.4.7)
Requires-Dist: python-dateutil (==2.8.2)
Requires-Dist: python-dotenv (==0.20.0)
Requires-Dist: python-slugify (==6.1.2)
Requires-Dist: pytz (==2022.1)
Requires-Dist: qudida (==0.0.4)
Requires-Dist: requests (==2.28.1)
Requires-Dist: requests-oauthlib (==1.3.1)
Requires-Dist: requests-toolbelt (==0.9.1)
Requires-Dist: responses (==0.18.0)
Requires-Dist: roboflow (==0.2.11)
Requires-Dist: rsa (==4.9)
Requires-Dist: scikit-image (==0.19.3)
Requires-Dist: scikit-learn (==1.1.1)
Requires-Dist: seaborn (==0.11.2)
Requires-Dist: selenium (==4.3.0)
Requires-Dist: shellingham (==1.5.0)
Requires-Dist: six (==1.16.0)
Requires-Dist: smmap (==5.0.0)
Requires-Dist: sniffio (==1.2.0)
Requires-Dist: sortedcontainers (==2.4.0)
Requires-Dist: soupsieve (==2.3.2.post1)
Requires-Dist: split-folders (==0.5.1)
Requires-Dist: stack-data (==0.3.0)
Requires-Dist: tensorboard (==2.9.1)
Requires-Dist: tensorboard-data-server (==0.6.1)
Requires-Dist: tensorboard-plugin-wit (==1.8.1)
Requires-Dist: text-unidecode (==1.3)
Requires-Dist: threadpoolctl (==3.1.0)
Requires-Dist: tifffile (==2022.8.3)
Requires-Dist: tomlkit (==0.11.4)
Requires-Dist: torch (==1.12.1)
Requires-Dist: torchvision (==0.13.1)
Requires-Dist: tqdm (==4.64.0)
Requires-Dist: traitlets (==5.3.0)
Requires-Dist: trio (==0.21.0)
Requires-Dist: trio-websocket (==0.9.2)
Requires-Dist: typing-extensions (==4.3.0)
Requires-Dist: urllib3 (==1.26.6)
Requires-Dist: validators (==0.20.0)
Requires-Dist: virtualenv (==20.16.3)
Requires-Dist: wcwidth (==0.2.5)
Requires-Dist: webdriver-manager (==3.8.3)
Requires-Dist: webencodings (==0.5.1)
Requires-Dist: wget (==3.2)
Requires-Dist: wsproto (==1.1.0)
Requires-Dist: xxhash (==3.0.0)
Requires-Dist: yarl (==1.8.1)
Requires-Dist: zipp (==3.8.1)
Project-URL: Repository, https://github.com/teamnebulaco/flockfysh
Description-Content-Type: text/markdown

## [![License](https://img.shields.io/badge/License-BSD_4--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause) [![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com) [![contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat)](https://github.com/teamnebulaco/flockfysh/contribute) [![PyPI version](https://badge.fury.io/py/flockfysh.svg)](https://badge.fury.io/py/flockfysh)


# Flockfysh: the data vending machine that gives more than it gets. 

flockfysh is an open source, efficient 2D-image tool that combines web scraping with artificial intelligence to generate and curate top quality image / object detection datasets. Feed flockfysh a "mini-dataset" with only ~50 images for each label (in the train category), and get back a hundredfold! 

We support your favorite tools such as [Roboflow](https://universe.roboflow.com/)!

We are currently looking for open source contributors, and would love to work with you to further develop this promising tool!

## Installation Recommendations
Currently, the dependencies appear are **clearly supported on Python 3.8** (the `requirements.txt` file was generated using a Python 3.8 virtual env). That would mean that it would likely work in other versions, but you may have to sort through the dependencies (a bunch of `pip install`s and lookups for the appropriate version)

**For Users**
Flockfysh now [has a CLI version on PyPi](https://pypi.org/project/flockfysh/0.0.1/) . One can simply run `pip install flockfysh` to download the package and then `flockfysh input.yaml` to run. The command line version is currently a prototype release, and please note that the repo contains the latest bug-updated versions.

## How flockfysh works in a nutshell
We power up traditional object detection and classic imaging techniques such as data augmentations with data gathering techniques like lightning-fast web-scraping. The higher level algorithm (for most of our supported features is the same) functions is as described below:

General procedure for training and webscraping ("train-scrape")
1. Train object detection models on the small sample of data provided (images solely in the `train` folder will be considered)
2. Scrape various websites for images (based on a small number of searches queries supplied by the user), and use the model to figure out the most relevant and quality images 
3. Download those images, and train an *even better* object detection model 
4. Repeat steps 2-3 for some iterations, and then use the best model to gather the rest of the data

## How flockfysh reads and processes tasks
Flockfysh utilizes a seamless format to run its basic tasks. We support multiple workflows to generate *quality* datasets. Our core tool expects a small dataset with a [simple format](#flockysh-dataset-format) to begin with and an [input file](#flockfysh-input-format-inputyaml), and then we will automatically generate the rest of the dataset

## Quick start - what you need to run flockfysh
- A dataset (in the format specified below)
- A .yaml input file

### Flockfysh dataset format
All of the flockfysh operations support datasets in the format shown below: 

```
dataset/
    train/ (preferrably shift the most of your images here)
    valid/ (validation set, please keep a small number of images here)
    test/  (not needed by flockfysh)
```

We choose this format because it is the most consistent with the majority of Machine Learning and Computer Vision workflows, as well as *a structure that supports model training and testing right away*.

*Note that the dataset labels should be in yolo / yolov5 format*

### Flockfysh input format (`input.yaml`) 
In order to run, flockfysh requires a small amount of guidance from the user to help some information. More specifically, it needs:

1. The names of your classes for your dataset
2. The input directory name of your dataset folder (in the format [above](#flockfysh-dataset-format))
3. A Python dictionary mapping each class name to a list of search queries that would get you the images you want 

We can effectively provide this information to flockfysh by using an input YAML file. Additionally, there are customizable settings (such as training parameters and auxiliary options such as saving the bounding boxes for each image) that you can also toggle in this YAML format.

Flockfysh uses a general format in the input YAML as follows:

```
job1:
    job-type: 'train-scrape'
    input-dir:
    ...
job2:
    ...
jobn:
    ...
```

Each task ("train-scrape" is an example of a task or feature that flockfysh can perform) is treated as a seperate job that flockfysh can do. flockfysh supports multiple job operations, and performs each one in a sequential manner (i.e, does `job1`, then `job2`, etc). The identifier for each job (ex: `job1`) can be changed to whatever the user wants, and when running, flockfysh will notify the user via Terminal when it starts a job. For more information on the different kinds of jobs, [see the link below](#more-about-the-various-flockfysh-jobs)

For each job in YAML, there are a set of *mandatory* settings to include (take a look at the 3 settings above, for example). The job will **not** complete (and an error will be thrown) if those mandatory settings are not included. There are also other *default, configurable parameters settings* for each job that are adopted if they are not specified. Specifying them in the YAML for that job will override the defaults (for that job only).

To take a look at the default options / confing for a specific job, check out the [default settings folder](https://github.com/teamnebulaco/flockfysh/tree/main/utilities/parse_config/default_params).


## A quick dive into running flockfysh
Make sure to check that you have everything specified in [link](#What-you-need). For most dataset generations, one can easily adapt a sample YAML workflow instead of needing to write one from scratch. 

Running flockfysh using the Github repo (latest code): 
1. Clone our repository by running the command `git clone https://github.com/teamnebulaco/flockfysh.git`
2. Run `cd flockfysh` to enter the repo and `pip install -r requirements.txt` to install the dependencies.
3. Export YoloV5 dataset (in format specified [above](#flockfysh-dataset-format)) into a folder inside the repository. If your dataset is on Roboflow, you have the option of exporting it and moving into the directory, or adding a download job at the beginning of the YAML to automatically load it in for you.
    - Don't have a dataset? Check out our [sample Roboflow dataset](https://github.com/teamnebulaco/sample-flockfysh-robo)
5. Create an `input.yaml` file (take a look at the sample `input.yaml` format)
6. Run `python run.py input.yaml` to run flockfysh with the specified input file `input.yaml`
    - On machines that use the command *python3* instead of *python* to execute Python 3, [change it to *python*](https://stackoverflow.com/questions/23048756/how-can-i-make-the-python-command-in-terminal-run-python3-instead-of-python2) or use the command *python3 run.py input.yaml* 

## Sample Workflows

### Auto-Downloading a Roboflow Dataset and Running a Train-Scrape Job
For the purposes of this sample, we will use a [publicly available dataset](https://universe.roboflow.com/sanka-madushankaresearch/insectbite) within the Roboflow universe.

The sample YAML file for this workflow is the same as the example `input.yaml`. 

1. After cloning the repo and getting set up, add this into a `input.yaml` file at the base directory (same directory as `run.py`)

```
job1: #Download the dataset we want to train
  job-type: 'download'
  api-name: 'roboflow'
  api-key: 'ENTER_YOUR_API_KEY_HERE'
  workspace-name: "sanka-madushankaresearch"
  project-name: "insectbite"
  project-version: 1
  output-dirname: 'robo'
job2: #job1 can be replaced with any name for the job you prefer
  job-type: 'train-scrape'
  input-dir: robo
  class-names: ['Bed Bug', 'Fire ant', 'Tick', 'Wasp']
  class-search-queries: {'Bed Bug' : ['bed bug bites'], 'Fire ant' : ['fire ant bites'], 'Tick' : ['tick bites'], 'Wasp' : ['wasp bites']}
  train-workers: 8
  images-per-label: 500
  total-maximum-images: 7000
  image-dimensions: 200
  train-batch: 8

```

2. Replace `api-key` with the API key you get from Roboflow (can easily be found when exporting a dataset using code).
3. Run `python run.py input.yaml` to run the workflow!

### Using a custom dataset to run a Train-Scrape Job
For the purposes of this sample, we will use a [publicly available dataset](https://universe.roboflow.com/sanka-madushankaresearch/insectbite) within the Roboflow universe, but locally download it. The dataset should be in the format specified [above](#flockfysh-dataset-format).


1. After cloning flockfysh and getting set up, run `git clone https://github.com/teamnebulaco/sample-flockfysh-robo.git` and move the `robo` folder inside into the base directory
2. Add the code below into a `input.yaml` file at the base directory (same directory as `run.py`)

```
job1: #job1 can be replaced with any name for the job you prefer
  job-type: 'train-scrape'
  input-dir: robo
  class-names: ['Bed Bug', 'Fire ant', 'Tick', 'Wasp']
  class-search-queries: {'Bed Bug' : ['bed bug bites'], 'Fire ant' : ['fire ant bites'], 'Tick' : ['tick bites'], 'Wasp' : ['wasp bites']}
  train-workers: 8
  images-per-label: 500
  total-maximum-images: 7000
  image-dimensions: 200
  train-batch: 8

```

3. Run `python run.py input.yaml` to run the workflow!

## More about the various flockfysh jobs 
You must specify which type of job you want for each using a `job-type` attribute. Here are the different job types available.

### download
Automatically downloads a dataset from a specific API. The current APIs supported are listed below:
- Roboflow
- Kaggle 
- HuggingFace

Note that each API also has API-specific information (API keys, secrets, etc) that flockfysh needs to utilize to download the dataset.

### train-scrape
Utilizes object detection models in tandem with web-scraping to generate an image-dataset. Here are some relevant properties:

- `input-dir`: The path to the dataset folder 
- `class-names`: An array of labels for the images you are trying to classify 
- `class-search-queries`: An array of words you'd put in a search (imagine Googling the images yourself) to download the images.
- `train-workers`: Number of workers for training
- `images-per-label`: MAIN PROPERTY TO control dataset size - how many images you want for each of the class names specified in `class-names`
- `total-maximum-images`: Adds an upper limit on the number of images (most support is for `images-per-label` at the moment)

## Development / Open Source
We are extremely excited to open this repository to the community, and can't wait to see the future to which this project heads! Please consider joining our Discord server, which we use as our main platform to communicate, improve, and resolve issues.

Steps to begin development: 
1. Clone our repository by running the command `git clone https://github.com/teamnebulaco/flockfysh.git`
2. Switch into our current dev_branch by running `git checkout -b dev-branch`
3. Pull the code. `git pull origin dev-branch`
3. Create a virtualenv by running the command `python -m virtualenv venv` (Syntax may vary)
    1. Note that the code above assumes **you have the virtualenv package installed** If not, run the command `pip install --upgrade virtualenv`
4. Run `python run.py input.yaml` to start developing! Happy coding!

## License
This repository is licensed under the [BSD-4 license](LICENSE.md). **Note that some of the images from the scraper may have artisitic copyrights, and should only, only, ONLY be used for ML & Training purposes. Under no grounds should this tool be exploited to circumvent copyrights.** Besides, it makes everyone's lives easier if we don't mooch off each other's copyrighted images. :))

