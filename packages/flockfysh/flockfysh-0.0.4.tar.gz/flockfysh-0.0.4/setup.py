# -*- coding: utf-8 -*-
from setuptools import setup

package_dir = \
{'': '.',
 'utilities': './utilities',
 'utilities.dataset_setup': './utilities/dataset_setup',
 'utilities.optimizers': './utilities/optimizers',
 'utilities.output_generation': './utilities/output_generation',
 'utilities.parse_config': './utilities/parse_config',
 'utilities.parse_config.default_params': './utilities/parse_config/default_params',
 'utilities.pipelines': './utilities/pipelines',
 'utilities.yolo_utils': './utilities/yolo_utils'}

packages = \
['scraper',
 'scraper.DataLoaders',
 'scraper.augmentations',
 'scraper.google_images',
 'scraper.shutterstock_images',
 'scraper.yahoo_images',
 'utilities',
 'utilities.dataset_setup',
 'utilities.optimizers',
 'utilities.output_generation',
 'utilities.parse_config',
 'utilities.parse_config.default_params',
 'utilities.pipelines',
 'utilities.yolo_utils']

package_data = \
{'': ['*']}

install_requires = \
['CacheControl==0.12.11',
 'GitPython==3.1.27',
 'Markdown==3.4.1',
 'MarkupSafe==2.1.1',
 'Pillow==9.0.1',
 'PySocks==1.7.1',
 'PyWavelets==1.3.0',
 'PyYAML==6.0',
 'Pygments==2.12.0',
 'SecretStorage==3.3.3',
 'Werkzeug==2.2.1',
 'absl-py==1.2.0',
 'aiohttp==3.8.1',
 'aiosignal==1.2.0',
 'albumentations==1.2.1',
 'asttokens==2.0.5',
 'async-timeout==4.0.2',
 'async_generator==1.10',
 'attrs==22.1.0',
 'backcall==0.2.0',
 'beautifulsoup4==4.11.1',
 'bs4==0.0.1',
 'cachetools==5.2.0',
 'cachy==0.3.0',
 'certifi==2021.5.30',
 'cffi==1.15.1',
 'chardet==4.0.0',
 'charset-normalizer==2.1.0',
 'cleo==0.8.1',
 'clikit==0.6.2',
 'crashtest==0.3.1',
 'cryptography==37.0.4',
 'cycler==0.10.0',
 'datasets==2.4.0',
 'decorator==5.1.1',
 'dill==0.3.5.1',
 'distlib==0.3.6',
 'executing==0.9.1',
 'filelock==3.7.1',
 'fonttools==4.34.4',
 'frozenlist==1.3.1',
 'fsspec==2022.7.1',
 'future==0.18.2',
 'gitdb==4.0.9',
 'glob2==0.7',
 'google-auth-oauthlib==0.4.6',
 'google-auth==2.10.0',
 'grpcio==1.47.0',
 'h11==0.13.0',
 'html5lib==1.1',
 'huggingface-hub==0.8.1',
 'idna==2.10',
 'imageio==2.21.0',
 'importlib-metadata==4.12.0',
 'imutils==0.5.4',
 'ipython==8.4.0',
 'jedi==0.18.1',
 'jeepney==0.8.0',
 'joblib==1.1.0',
 'kaggle==1.5.12',
 'keyring==23.8.2',
 'kiwisolver==1.3.1',
 'lockfile==0.12.2',
 'lxml==4.9.1',
 'matplotlib-inline==0.1.3',
 'matplotlib==3.5.2',
 'msgpack==1.0.4',
 'multidict==6.0.2',
 'multiprocess==0.70.13',
 'networkx==2.8.5',
 'numpy==1.23.1',
 'oauthlib==3.2.0',
 'opencv-python-headless==4.2.0.32',
 'opencv-python==4.2.0.32',
 'outcome==1.2.0',
 'packaging==20.9',
 'pandas==1.4.3',
 'parso==0.8.3',
 'pastel==0.2.1',
 'pefile==2022.5.30',
 'pexpect==4.8.0',
 'pickleshare==0.7.5',
 'pkginfo==1.8.3',
 'platformdirs==2.5.2',
 'poetry-core==1.0.8',
 'poetry==1.1.15',
 'prompt-toolkit==3.0.30',
 'protobuf==3.19.4',
 'psutil==5.9.1',
 'ptyprocess==0.7.0',
 'pure-eval==0.2.2',
 'pyOpenSSL==22.0.0',
 'pyarrow==9.0.0',
 'pyasn1-modules==0.2.8',
 'pyasn1==0.4.8',
 'pycparser==2.21',
 'pylev==1.4.0',
 'pyparsing==2.4.7',
 'python-dateutil==2.8.2',
 'python-dotenv==0.20.0',
 'python-slugify==6.1.2',
 'pytz==2022.1',
 'qudida==0.0.4',
 'requests-oauthlib==1.3.1',
 'requests-toolbelt==0.9.1',
 'requests==2.28.1',
 'responses==0.18.0',
 'roboflow==0.2.11',
 'rsa==4.9',
 'scikit-image==0.19.3',
 'scikit-learn==1.1.1',
 'seaborn==0.11.2',
 'selenium==4.3.0',
 'shellingham==1.5.0',
 'six==1.16.0',
 'smmap==5.0.0',
 'sniffio==1.2.0',
 'sortedcontainers==2.4.0',
 'soupsieve==2.3.2.post1',
 'split-folders==0.5.1',
 'stack-data==0.3.0',
 'tensorboard-data-server==0.6.1',
 'tensorboard-plugin-wit==1.8.1',
 'tensorboard==2.9.1',
 'text-unidecode==1.3',
 'threadpoolctl==3.1.0',
 'tifffile==2022.8.3',
 'tomlkit==0.11.4',
 'torch==1.12.1',
 'torchvision==0.13.1',
 'tqdm==4.64.0',
 'traitlets==5.3.0',
 'trio-websocket==0.9.2',
 'trio==0.21.0',
 'typing-extensions==4.3.0',
 'urllib3==1.26.6',
 'validators==0.20.0',
 'virtualenv==20.16.3',
 'wcwidth==0.2.5',
 'webdriver-manager==3.8.3',
 'webencodings==0.5.1',
 'wget==3.2',
 'wsproto==1.1.0',
 'xxhash==3.0.0',
 'yarl==1.8.1',
 'zipp==3.8.1']

entry_points = \
{'console_scripts': ['flockfysh = run:run']}

setup_kwargs = {
    'name': 'flockfysh',
    'version': '0.0.4',
    'description': 'A simple images vending machine that gives more than it gets.',
    'long_description': '## [![License](https://img.shields.io/badge/License-BSD_4--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause) [![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com) [![contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat)](https://github.com/teamnebulaco/flockfysh/contribute) [![PyPI version](https://badge.fury.io/py/flockfysh.svg)](https://badge.fury.io/py/flockfysh)\n\n\n# Flockfysh: the data vending machine that gives more than it gets. \n\nflockfysh is an open source, efficient 2D-image tool that combines web scraping with artificial intelligence to generate and curate top quality image / object detection datasets. Feed flockfysh a "mini-dataset" with only ~50 images for each label (in the train category), and get back a hundredfold! \n\nWe support your favorite tools such as [Roboflow](https://universe.roboflow.com/)!\n\n- [Quickstart](#a-quick-dive-into-running-flockfysh)\n\nWe are currently looking for open source contributors, and would love to work with you to further develop this promising tool!\n\n## Installation Recommendations\nCurrently, the dependencies appear are **clearly supported on Python 3.8** (the `requirements.txt` file was generated using a Python 3.8 virtual env). That would mean that it would likely work in other versions, but you may have to sort through the dependencies (a bunch of `pip install`s and lookups for the appropriate version)\n\n**For Users**\nFlockfysh now [has a CLI version on PyPi](https://pypi.org/project/flockfysh/0.0.1/) . One can simply run `pip install flockfysh` to download the package and then `flockfysh input.yaml` to run. \n\n## How flockfysh works in a nutshell\nWe power up traditional object detection and classic imaging techniques such as data augmentations with data gathering techniques like lightning-fast web-scraping. The higher level algorithm (for most of our supported features is the same) functions is as described below:\n\nGeneral procedure for training and webscraping ("train-scrape")\n1. Train object detection models on the small sample of data provided (images solely in the `train` folder will be considered)\n2. Scrape various websites for images (based on a small number of searches queries supplied by the user), and use the model to figure out the most relevant and quality images \n3. Download those images, and train an *even better* object detection model \n4. Repeat steps 2-3 for some iterations, and then use the best model to gather the rest of the data\n\n## How flockfysh reads and processes tasks\nFlockfysh utilizes a seamless format to run its basic tasks. We support multiple workflows to generate *quality* datasets. Our core tool expects a small dataset with a [simple format](#flockysh-dataset-format) to begin with and an [input file](#flockfysh-input-format-inputyaml), and then we will automatically generate the rest of the dataset\n\n## What you need to run flockfysh\n- A dataset (in the format specified below)\n- A .yaml input file\n\n### Flockfysh dataset format\nAll of the flockfysh operations support datasets in the format shown below: \n\n```\ndataset/\n    train/ (preferrably shift the most of your images here)\n    valid/ (validation set, please keep a small number of images here)\n    test/  (not needed by flockfysh)\n```\n\nWe choose this format because it is the most consistent with the majority of Machine Learning and Computer Vision workflows, as well as *a structure that supports model training and testing right away*.\n\n*Note that the dataset labels should be in yolo / yolov5 format*\n\n### Flockfysh input format (`input.yaml`) \nIn order to run, flockfysh requires a small amount of guidance from the user to help some information. More specifically, it needs:\n\n1. The names of your classes for your dataset\n2. The input directory name of your dataset folder (in the format [above](#flockfysh-dataset-format))\n3. A Python dictionary mapping each class name to a list of search queries that would get you the images you want \n\nWe can effectively provide this information to flockfysh by using an input YAML file. Additionally, there are customizable settings (such as training parameters and auxiliary options such as saving the bounding boxes for each image) that you can also toggle in this YAML format.\n\nFlockfysh uses a general format in the input YAML as follows:\n\n```\njob1:\n    job-type: \'train-scrape\'\n    input-dir:\n    ...\njob2:\n    ...\njobn:\n    ...\n```\n\nEach task ("train-scrape" is an example of a task or feature that flockfysh can perform) is treated as a seperate job that flockfysh can do. flockfysh supports multiple job operations, and performs each one in a sequential manner (i.e, does `job1`, then `job2`, etc). The identifier for each job (ex: `job1`) can be changed to whatever the user wants, and when running, flockfysh will notify the user via Terminal when it starts a job. For more information on the different kinds of jobs, [see the link below](#more-about-the-various-flockfysh-jobs)\n\nFor each job in YAML, there are a set of *mandatory* settings to include (take a look at the 3 settings above, for example). The job will **not** complete (and an error will be thrown) if those mandatory settings are not included. There are also other *default, configurable parameters settings* for each job that are adopted if they are not specified. Specifying them in the YAML for that job will override the defaults (for that job only).\n\nTo take a look at the default options / confing for a specific job, check out the [default settings folder](https://github.com/teamnebulaco/flockfysh/tree/main/utilities/parse_config/default_params).\n\n\n## A quick dive into running flockfysh\nMake sure to check that you have everything specified in [link](#what-you-need-to-run-flockfysh). For most dataset generations, one can easily adapt a sample YAML workflow instead of needing to write one from scratch. \n\nRunning flockfysh using the Github repo (latest code): \n1. Clone our repository by running the command `git clone https://github.com/teamnebulaco/flockfysh.git`\n2. Run `cd flockfysh` to enter the repo and `pip install -r requirements.txt` to install the dependencies.\n3. Export YoloV5 dataset (in format specified [above](#flockfysh-dataset-format)) into a folder inside the repository. If your dataset is on Roboflow, you have the option of exporting it and moving into the directory, or adding a download job at the beginning of the YAML to automatically load it in for you.\n    - Don\'t have a dataset? Check out our [sample Roboflow dataset](https://github.com/teamnebulaco/sample-flockfysh-robo)\n5. Create an `input.yaml` file (take a look at the sample `input.yaml` format)\n6. Run `python run.py input.yaml` to run flockfysh with the specified input file `input.yaml`\n    - On machines that use the command *python3* instead of *python* to execute Python 3, [change it to *python*](https://stackoverflow.com/questions/23048756/how-can-i-make-the-python-command-in-terminal-run-python3-instead-of-python2) or use the command *python3 run.py input.yaml* \n\n## Sample Workflows\n\n### Auto-Downloading a Roboflow Dataset and Running a Train-Scrape Job\nFor the purposes of this sample, we will use a [publicly available dataset](https://universe.roboflow.com/sanka-madushankaresearch/insectbite) within the Roboflow universe.\n\nThe sample YAML file for this workflow is the same as the example `input.yaml`. \n\n1. After cloning the repo and getting set up, add this into a `input.yaml` file at the base directory (same directory as `run.py`)\n\n```\njob1: #Download the dataset we want to train\n  job-type: \'download\'\n  api-name: \'roboflow\'\n  api-key: \'ENTER_YOUR_API_KEY_HERE\'\n  workspace-name: "sanka-madushankaresearch"\n  project-name: "insectbite"\n  project-version: 1\n  output-dirname: \'robo\'\njob2: #job1 can be replaced with any name for the job you prefer\n  job-type: \'train-scrape\'\n  input-dir: robo\n  class-names: [\'Bed Bug\', \'Fire ant\', \'Tick\', \'Wasp\']\n  class-search-queries: {\'Bed Bug\' : [\'bed bug bites\'], \'Fire ant\' : [\'fire ant bites\'], \'Tick\' : [\'tick bites\'], \'Wasp\' : [\'wasp bites\']}\n  train-workers: 8\n  images-per-label: 500\n  total-maximum-images: 7000\n  image-dimensions: 200\n  train-batch: 8\n\n```\n\n2. Replace `api-key` with the API key you get from Roboflow (can easily be found when exporting a dataset using code).\n3. Run `python run.py input.yaml` to run the workflow!\n\n### Using a custom dataset to run a Train-Scrape Job\nFor the purposes of this sample, we will use a [publicly available dataset](https://universe.roboflow.com/sanka-madushankaresearch/insectbite) within the Roboflow universe, but locally download it. The dataset should be in the format specified [above](#flockfysh-dataset-format).\n\n\n1. After cloning flockfysh and getting set up, run `git clone https://github.com/teamnebulaco/sample-flockfysh-robo.git` and move the `robo` folder inside into the base directory\n2. Add the code below into a `input.yaml` file at the base directory (same directory as `run.py`)\n\n```\njob1: #job1 can be replaced with any name for the job you prefer\n  job-type: \'train-scrape\'\n  input-dir: robo\n  class-names: [\'Bed Bug\', \'Fire ant\', \'Tick\', \'Wasp\']\n  class-search-queries: {\'Bed Bug\' : [\'bed bug bites\'], \'Fire ant\' : [\'fire ant bites\'], \'Tick\' : [\'tick bites\'], \'Wasp\' : [\'wasp bites\']}\n  train-workers: 8\n  images-per-label: 500\n  total-maximum-images: 7000\n  image-dimensions: 200\n  train-batch: 8\n\n```\n\n3. Run `python run.py input.yaml` to run the workflow!\n\n## More about the various flockfysh jobs \nYou must specify which type of job you want for each using a `job-type` attribute. Here are the different job types available.\n\n### download\nAutomatically downloads a dataset from a specific API. The current APIs supported are listed below:\n- Roboflow\n- Kaggle \n- HuggingFace\n\nNote that each API also has API-specific information (API keys, secrets, etc) that flockfysh needs to utilize to download the dataset.\n\n### train-scrape\nUtilizes object detection models in tandem with web-scraping to generate an image-dataset. Here are some relevant properties:\n\n- `input-dir`: The path to the dataset folder \n- `class-names`: An array of labels for the images you are trying to classify \n- `class-search-queries`: An array of words you\'d put in a search (imagine Googling the images yourself) to download the images.\n- `train-workers`: Number of workers for training\n- `images-per-label`: MAIN PROPERTY TO control dataset size - how many images you want for each of the class names specified in `class-names`\n- `total-maximum-images`: Adds an upper limit on the number of images (most support is for `images-per-label` at the moment)\n\n## Development / Open Source\nWe are extremely excited to open this repository to the community, and can\'t wait to see the future to which this project heads! Please consider joining our Discord server, which we use as our main platform to communicate, improve, and resolve issues.\n\nSteps to begin development: \n1. Clone our repository by running the command `git clone https://github.com/teamnebulaco/flockfysh.git`\n2. Switch into our current dev_branch by running `git checkout -b dev-branch`\n3. Pull the code. `git pull origin dev-branch`\n3. Create a virtualenv by running the command `python -m virtualenv venv` (Syntax may vary)\n    1. Note that the code above assumes **you have the virtualenv package installed** If not, run the command `pip install --upgrade virtualenv`\n4. Run `python run.py input.yaml` to start developing! Happy coding!\n\n## License\nThis repository is licensed under the [BSD-4 license](LICENSE.md). **Note that some of the images from the scraper may have artisitic copyrights, and should only, only, ONLY be used for ML & Training purposes. Under no grounds should this tool be exploited to circumvent copyrights.** Besides, it makes everyone\'s lives easier if we don\'t mooch off each other\'s copyrighted images. :))\n\n## A major thank you to everyone who has pitched in to making flockfysh what it is today!\n<a href="https://github.com/teamnebulaco/flockfysh/graphs/contributors">\n  <img src="https://contrib.rocks/image?repo=teamnebulaco/flockfysh" />\n</a>\n',
    'author': 'Team Nebula',
    'author_email': 'teamnebulaco@gmail.com',
    'maintainer': 'None',
    'maintainer_email': 'None',
    'url': 'https://github.com/teamnebulaco/flockfysh',
    'package_dir': package_dir,
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'entry_points': entry_points,
    'python_requires': '>=3.8,<3.12',
}


setup(**setup_kwargs)
